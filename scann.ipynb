{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScaNN\n",
    "---\n",
    "## Download Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: h5py in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (3.9.0)\n",
      "Requirement already satisfied: requests in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: scann in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (1.2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from requests) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: tensorflow~=2.13.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from scann) (2.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (1.59.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (2.3.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow~=2.13.0->scann)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorflow~=2.13.0->scann) (0.34.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->scann) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/sachin/anaconda3/envs/r-lab/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->scann) (3.2.2)\n",
      "Installing collected packages: typing-extensions\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic-core 2.10.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic 2.4.2 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy h5py requests scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 09:17:22.968497: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-14 09:17:23.205637: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-14 09:17:23.206704: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-14 09:17:24.190828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    response = requests.get(\"http://ann-benchmarks.com/sift-128-euclidean.hdf5\")\n",
    "    loc = os.path.join(tmp, \"sift.hdf5\")\n",
    "    with open(loc, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    sift_h5py = h5py.File(loc, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distances', 'neighbors', 'test', 'train']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sift_h5py.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 128)\n",
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "dataset = sift_h5py['train']\n",
    "queries = sift_h5py['test']\n",
    "print(dataset.shape)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ScaNN Searcher\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 09:20:49.496407: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 249544\n",
      "2023-10-14 09:20:55.523612: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:84] PartitionerFactory ran in 6.027129817s.\n"
     ]
    }
   ],
   "source": [
    "normalized_dataset = dataset / np.linalg.norm(dataset, axis=1)[:, np.newaxis]\n",
    "# configure ScaNN as a tree - asymmetric hash hybrid with reordering\n",
    "# anisotropic quantization as described in the paper; see README\n",
    "\n",
    "# use scann.scann_ops.build() to instead create a TensorFlow-compatible searcher\n",
    "searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").tree(\n",
    "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
    "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(neighbors, true_neighbors):\n",
    "    total = 0\n",
    "    for gt_row, row in zip(true_neighbors, neighbors):\n",
    "        total += np.intersect1d(gt_row, row).shape[0]\n",
    "    return total / true_neighbors.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScaNN interface features\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.98078\n",
      "Time: 1.257188320159912\n"
     ]
    }
   ],
   "source": [
    "# this will search the top 100 of the 2000 leaves, and compute\n",
    "# the exact dot products of the top 100 candidates from asymmetric\n",
    "# hashing to get the final top 10 candidates.\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "end = time.time()\n",
    "\n",
    "# we are given top 100 neighbors in the ground truth, so select top 10\n",
    "print(\"Recall:\", compute_recall(neighbors, sift_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.98533\n",
      "Time: 1.6079840660095215\n"
     ]
    }
   ],
   "source": [
    "# increasing the leaves to search increases recall at the cost of speed\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries, leaves_to_search=150)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recall:\", compute_recall(neighbors, sift_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.98934\n",
      "Time: 1.995032548904419\n"
     ]
    }
   ],
   "source": [
    "# increasing reordering (the exact scoring of top AH candidates) has a similar effect.\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries, leaves_to_search=150, pre_reorder_num_neighbors=250)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recall:\", compute_recall(neighbors, sift_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000, 10)\n",
      "(10000, 20) (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "# we can also dynamically configure the number of neighbors returned\n",
    "# currently returns 10 as configued in ScannBuilder()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "print(neighbors.shape, distances.shape)\n",
    "\n",
    "# now returns 20\n",
    "neighbors, distances = searcher.search_batched(queries, final_num_neighbors=20)\n",
    "print(neighbors.shape, distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[932085 934876 561813 708177 706771]\n",
      "[454.80237 453.99243 449.59064 443.9261  443.51404]\n",
      "Latency (ms): 0.4856586456298828\n"
     ]
    }
   ],
   "source": [
    "# we have been exclusively calling batch search so far; the single-query call has the same API\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search(queries[0], final_num_neighbors=5)\n",
    "end = time.time()\n",
    "\n",
    "print(neighbors)\n",
    "print(distances)\n",
    "print(\"Latency (ms):\", 1000*(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
